{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow ver. 2.4.1\n"
     ]
    }
   ],
   "source": [
    "#Import Statements\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "rng = default_rng()\n",
    "from datetime import timedelta\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import time as time\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import glob\n",
    "import random\n",
    "import sys\n",
    "from mpl_toolkits.axes_grid1.axes_divider import make_axes_locatable\n",
    "\n",
    "from os.path import expanduser\n",
    "home = expanduser(\"~\")\n",
    "sys.path.append(home+'/repos/ClusNet/code/modules/')\n",
    "\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from ClusNet import Cluster\n",
    "from ClusNet import model as m\n",
    "from ClusNet import dataset as ds\n",
    "sys.path.append(home+'/repos/ClusNet/CNN/seg/')\n",
    "import seg\n",
    "\n",
    "import glob\n",
    "import IPython.display as display\n",
    "import datetime, os\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.gridspec as gridspec\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# For more information about autotune:\n",
    "# https://www.tensorflow.org/guide/data_performance#prefetching\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "print(f\"Tensorflow ver. {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusglob = glob.glob(home + '/repos/ClusNet/data/eROSITA_no_background/*.fits')\n",
    "\n",
    "data_length = 200\n",
    "\n",
    "paths = random.choices(clusglob,k=data_length)\n",
    "IMG_SIZE = 384\n",
    "N_CLASSES = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model directory created --> /Users/erebor/repos/ClusNet/models/seg/AYAWd\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "make_dataset() got an unexpected keyword argument 'paths'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-cf7f035bc736>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodeldir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhome\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/repos/ClusNet/models/seg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m x_train,y_train,paths_train,x_test,y_test,paths_test = seg.make_dataset(paths=paths,\n\u001b[0m\u001b[1;32m      3\u001b[0m                                                                     \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.90\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                                     \u001b[0mmodeldir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodeldir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                                     \u001b[0mshift\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: make_dataset() got an unexpected keyword argument 'paths'"
     ]
    }
   ],
   "source": [
    "modeldir = Cluster.mkdir_model(spath=home+'/repos/ClusNet/models/seg')\n",
    "x_train,y_train,paths_train,x_test,y_test,paths_test = seg.make_dataset(paths=paths,\n",
    "                                                                    validation_split=0.90,\n",
    "                                                                    modeldir=modeldir,\n",
    "                                                                    shift=False,\n",
    "                                                                    agn=True,\n",
    "                                                                    poisson=True,\n",
    "                                                                    sigma=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t = tf.keras.utils.to_categorical(y_train[idx], num_classes=3)\n",
    "print(t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.randint(0,x_train.shape[0])\n",
    "mask = y_train[idx]\n",
    "image = x_train[idx]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,5),ncols=2,nrows=2,sharex=True,sharey=True)\n",
    "idx = np.random.randint(0,image.shape[0])\n",
    "cmap = mpl.cm.binary\n",
    "vmin, vmax = np.nanmin(mask), np.nanmax(mask)\n",
    "norm = mpl.colors.Normalize(vmin=vmin,vmax=vmax)\n",
    "\n",
    "ax[0][0].imshow(image,\n",
    "             cmap=cmap,\n",
    "             interpolation='none',\n",
    "             norm=norm, aspect = 1)\n",
    "\n",
    "    \n",
    "ax[0][1].imshow(mask[:,:,0],\n",
    "             cmap=mpl.cm.Blues,\n",
    "             interpolation='none', aspect = 1)\n",
    "ax[1][0].imshow(mask[:,:,1],\n",
    "             cmap=mpl.cm.Reds,\n",
    "             interpolation='none', aspect = 1)\n",
    "ax[1][1].imshow(mask[:,:,2],\n",
    "             cmap=mpl.cm.Greens,\n",
    "             interpolation='none', aspect = 1)\n",
    "\n",
    "for ax_ in ax.reshape(-1):\n",
    "    #ax[i].axis('off')\n",
    "    ax_.set_xticks([])\n",
    "    ax_.set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0, hspace=0)\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "maybe something other than maxpooling?\n",
    "running it for longer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat = tf.keras.layers.Concatenate(axis=3)\n",
    "# (batch_size,img_size,img_size,channel)\n",
    "# (0,1,2,3)\n",
    "input_shape = (IMG_SIZE,IMG_SIZE,1)\n",
    "\n",
    "x0 = keras.Input(shape=input_shape)\n",
    "\n",
    "elayer1 = keras.Sequential()\n",
    "elayer1.add(layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\", padding='same'))\n",
    "elayer1.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "x1 = elayer1(x0)\n",
    "\n",
    "elayer2 = keras.Sequential()\n",
    "elayer2.add(layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\", padding='same'))\n",
    "elayer2.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "x2 = elayer2(x1)\n",
    "\n",
    "elayer3 = keras.Sequential()\n",
    "elayer3.add(layers.Conv2D(16, kernel_size=(3, 3), activation=\"relu\", padding='same'))\n",
    "elayer3.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "x3 = elayer3(x2)\n",
    "\n",
    "elayer4 = keras.Sequential()\n",
    "elayer4.add(layers.Conv2D(8, kernel_size=(3, 3), activation=\"relu\", padding='same'))\n",
    "elayer4.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "x4 = elayer4(x3)\n",
    "\n",
    "dlayer1 = keras.Sequential()\n",
    "dlayer1.add(layers.Conv2DTranspose(8, kernel_size=(3, 3), activation=\"relu\", padding='same'))\n",
    "dlayer1.add(layers.UpSampling2D((2, 2)))\n",
    "\n",
    "x5 = dlayer1(x4)\n",
    "\n",
    "x6 = concat([x5,x3])\n",
    "\n",
    "dlayer2 = keras.Sequential()\n",
    "dlayer2.add(layers.Conv2DTranspose(16, kernel_size=(3, 3), activation=\"relu\", padding='same'))\n",
    "dlayer2.add(layers.UpSampling2D((2, 2)))\n",
    "\n",
    "x7 = dlayer2(x6)\n",
    "\n",
    "x8 = concat([x7, x2])\n",
    "\n",
    "dlayer3 = keras.Sequential()\n",
    "dlayer3.add(layers.Conv2DTranspose(32, kernel_size=(3, 3), activation=\"relu\", padding='same'))\n",
    "dlayer3.add(layers.UpSampling2D((2, 2)))\n",
    "\n",
    "x9 = dlayer3(x8)\n",
    "\n",
    "x10 = concat([x9, x1])\n",
    "\n",
    "dlayer4 = keras.Sequential()\n",
    "dlayer4.add(layers.Conv2DTranspose(64, kernel_size=(3, 3), activation=\"relu\", padding='same'))\n",
    "dlayer4.add(layers.UpSampling2D((2, 2)))\n",
    "\n",
    "x11 = dlayer4(x10)\n",
    "\n",
    "x12 = concat([x11, x0])\n",
    "\n",
    "x13 = layers.Conv2DTranspose(3, (1, 1), activation='relu')(x12)\n",
    "\n",
    "output= x13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_U = tf.keras.Model(x0, output)\n",
    "\n",
    "#loss = tf.keras.metrics.MeanIoU(num_classes=3)\n",
    "#loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "loss = 'mse'\n",
    "\n",
    "optimizer=tf.keras.optimizers.Adam(lr=1e-5)\n",
    "\n",
    "\n",
    "the_U.compile(optimizer=optimizer, \n",
    "              loss=loss,\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_U.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 16\n",
    "validation_split = 0.09\n",
    "print(\"\\n********LEARNING START********\")\n",
    "start = time.time()\n",
    "training_start = time.time()\n",
    "# Train the model on the normalized training set.\n",
    "history = the_U.fit(x=x_train, \n",
    "                    y=y_train, \n",
    "                    batch_size=batch_size, \n",
    "                    epochs=epochs, \n",
    "                    verbose=1, \n",
    "                    validation_split=validation_split)\n",
    "\n",
    "epochs = history.epoch\n",
    "hist = pd.DataFrame(history.history)\n",
    "\n",
    "elapsed = time.time() - start\n",
    "print(\"\\nTIME:\",str(timedelta(seconds=elapsed)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n Evaluate the new model against the test set:\")\n",
    "#print(the_U.evaluate(x=x_test, y=y_test, batch_size=batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = the_U(x_test, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5),nrows=1,ncols=3,sharex=True,sharey=True)\n",
    "idx = np.random.randint(0,prediction.shape[0])\n",
    "cmap = mpl.cm.binary\n",
    "norm = mpl.colors.Normalize(vmin=0, vmax=1)\n",
    "labels = ['cluster','agn','intersect']\n",
    "for i in range(3):\n",
    "    print(np.nanmin(prediction[idx,:,:,i]),np.nanmax(prediction[0,:,:,i]))\n",
    "    im = ax[i].imshow(prediction[idx,:,:,i],interpolation='none',cmap=cmap,norm=norm)\n",
    "    ax[i].set_title(labels[i])\n",
    "#plt.colorbar(im)\n",
    "cax = fig.add_axes([1, 0.25, 0.01, 0.5])\n",
    "cbar = mpl.colorbar.ColorbarBase(cax, cmap=cmap, norm = norm)\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(wspace=0.05)\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,5),nrows=1,ncols=3,sharex=True,sharey=True)\n",
    "idx = np.random.randint(0,prediction.shape[0])\n",
    "cmap = mpl.cm.binary\n",
    "norm = mpl.colors.Normalize(vmin=0, vmax=1)\n",
    "labels = ['cluster','agn','intersect']\n",
    "for i in range(3):\n",
    "    print(np.nanmin(y_test[idx,:,:,i]),np.nanmax(y_test[0,:,:,i]))\n",
    "    im = ax[i].imshow(y_test[idx,:,:,i],interpolation='none',cmap=cmap,norm=norm)\n",
    "    ax[i].set_title(labels[i])\n",
    "#plt.colorbar(im)\n",
    "cax = fig.add_axes([1, 0.25, 0.01, 0.5])\n",
    "cbar = mpl.colorbar.ColorbarBase(cax, cmap=cmap, norm = norm)\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(wspace=0.05)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7,5),nrows=2,ncols=3,sharex=True,sharey=True)\n",
    "idx = np.random.randint(0,prediction.shape[0])\n",
    "cmap = mpl.cm.binary\n",
    "norm = mpl.colors.Normalize(vmin=0, vmax=1)\n",
    "labels = ['cluster','agn','intersect']\n",
    "\n",
    "cmaps = [mpl.cm.Blues,mpl.cm.Reds,mpl.cm.Greens]\n",
    "for i in range(3):\n",
    "    \n",
    "    im = ax[0][i].imshow(y_test[idx,:,:,i],interpolation='none',cmap=cmaps[i],norm=norm)\n",
    "    im = ax[1][i].imshow(prediction[idx,:,:,i],interpolation='none',cmap=cmaps[i],norm=norm)\n",
    "    ax[0][i].set_title(labels[i])\n",
    "    ax[0][i].set_aspect('equal'),ax[1][i].set_aspect('equal')\n",
    "    ax[0][i].set_xticks([]),ax[1][i].set_xticks([])\n",
    "    ax[0][i].set_yticks([]),ax[1][i].set_yticks([])\n",
    "\n",
    "ax[0][0].set_ylabel('Input',fontsize=12)\n",
    "ax[1][0].set_ylabel('Ouput',fontsize=12)\n",
    "#cax = fig.add_axes([1, 0.25, 0.01, 0.5])\n",
    "#cbar = mpl.colorbar.ColorbarBase(cax, cmap=cmap, norm = norm)\n",
    "\n",
    "plt.subplots_adjust(wspace=-.3,hspace=0)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection_over_union(prediction, labels):\n",
    "    pred = tf.argmax(prediction, axis=1)\n",
    "    labl = tf.constant(labels)\n",
    "    return iou, conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for j in range(10):\n",
    "    fig, ax = plt.subplots(figsize=(7,7),nrows=3,ncols=3,sharex=True,sharey=True)\n",
    "    idx = np.random.randint(0,prediction.shape[0])\n",
    "    cmap = mpl.cm.binary\n",
    "    norm = mpl.colors.Normalize(vmin=0, vmax=1)\n",
    "    labels = ['cluster','agn','intersect']\n",
    "\n",
    "    cmaps = [mpl.cm.Blues,mpl.cm.Reds,mpl.cm.Greens]\n",
    "    for i in range(3):\n",
    "\n",
    "        input_ = y_test[idx,:,:,i]\n",
    "        output_ = prediction[idx,:,:,i]\n",
    "        contrast = output_-input_\n",
    "        im = ax[0][i].imshow(input_,interpolation='none',cmap=cmaps[i],norm=norm)\n",
    "        im = ax[1][i].imshow(output_,interpolation='none',cmap=cmaps[i],norm=norm)\n",
    "        im = ax[2][i].imshow(contrast,interpolation='none',cmap=cmaps[i],norm=norm)\n",
    "\n",
    "        ax[0][i].set_title(labels[i])\n",
    "        for j in range(2):\n",
    "            ax[j][i].set_aspect('equal')\n",
    "            ax[j][i].set_xticks([])\n",
    "            ax[j][i].set_yticks([])\n",
    "\n",
    "    ax[0][0].set_ylabel('Input',fontsize=12)\n",
    "    ax[1][0].set_ylabel('Ouput',fontsize=12)\n",
    "    ax[2][0].set_ylabel('Contrast',fontsize=12)\n",
    "\n",
    "    #cax = fig.add_axes([1, 0.25, 0.01, 0.5])\n",
    "    #cbar = mpl.colorbar.ColorbarBase(cax, cmap=cmap, norm = norm)\n",
    "\n",
    "    plt.subplots_adjust(wspace=-.5,hspace=0)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    \n",
    "    m = tf.metrics.MeanIoU(num_classes=4)\n",
    "    m.update_state(input_, output_)\n",
    "    mean_iou = m.result().numpy()\n",
    "    print(mean_iou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEAN_IOUs = []\n",
    "M500s = []\n",
    "ROCs =[]\n",
    "for idx, path in enumerate(paths_test):\n",
    "    x = Cluster.Cluster(fpath=path)\n",
    "    \n",
    "    m = tf.metrics.MeanIoU(num_classes=4)\n",
    "    true = y_test[idx,:,:,:]\n",
    "    pred = prediction[idx,:,:,:]\n",
    "    m.update_state(true,pred)\n",
    "    mean_iou = m.result().numpy()\n",
    "    MEAN_IOUs.append(mean_iou)\n",
    "    \n",
    "    M500 = np.array(x.M500)\n",
    "    M500s.append(M500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auroc(true, pred):\n",
    "    return tf.py_function(roc_auc_score, (true, pred), tf.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ROCs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "new_x, new_y = zip(*sorted(zip(M500s, MEAN_IOUs)))\n",
    "plt.plot(new_x,new_y, label='Mean IoU')\n",
    "\n",
    "plt.xlabel('M500c')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
