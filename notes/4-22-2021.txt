Done over last week:
    - got BlueCrabs working (finally)
        - somehow worked without marcc help
        - but still want to ask MARCC help how these paritions work and what the issue was
        - use interact commands
            - GPUs = 4
            - CPUs = 24
            - partition = gpuk80
            - nodelist = gpu019
    - ran first classification model with eROSITA data
        - cluster or not?

Questions:
- classification model = 'category/bQblI'
    - goal: is or is not a cluster present?
    - classification (1 output neuron)
        - 0 for no cluster (just poisson noise)
        - 1 for cluster
    - initial modeling:
        - opt: 'sgd'
        - act: 'sigmoid'
        - loss: 'BinaryCrossentropy'
        - epochs: 100
        - 384 x 384
        - Data sample:
            - ~1800 clusters (80% of total sample)
            - ~1800 negatives
            - add. 20% validation cut
                - ~1500 training clusters
        - runtime: ~40 minutes

Issues with model:
    - from the get-go training set outperformed validation set
    - all output neurons (validation and training) is 0.6
    - weird accuracy for validation (0 for all epochs)
    
Suspected issue:
    - incorrect loading of dataset
        - negatives and positives input order is not randomized
            - e.g. validation only has negatives because it takes last 20% of dataset
            - dataset split in first half to positives, second half to negatives
To-do:
    - fix issue with initial model (probably random locations of dataset)
    - implement ROC curves to test performance once we have a reasonable model
    
------

Old regression model found
- goal: find sigma of gaussian, center of gaussian in xy
- epochs = 1000
------
Other questions:
    - how to grab the history of a previously saved model?
        - want to plot loss/accuracy of any saved model
    - fundamentally, is classification just a regression model with one label?
    - is the order of labels or images randomized when fitting/training a model?
    - how can I efficently save the unique data set I train a model with, and reload if necessary?
    
    
----

Suggestions from michelle:
    - same random numbers every time you run
    - change to the seed, random
    - setting a random set makes code reproduce-able
    - increase batch_size 
    
    
model suggestions from Michelle:
    - use Adam optimizer at first, and then use sgd
    - guess: probably need more epochs, but sgd uses a lot of epochs, so use adam first
    - use Adam optimizer with an overnight run (~1000 - 2000 epochs)
    - saving every 100th epoch try to save model --> large memory, save to scratch folder
    - swap out binary cross-entropy with something else? loss function can make a big difference
    - if lasting issue: check for indexing issues (clusters are not labeled or randomized correctly?)
    
    - run multiple models at the same time
       - use flags in command line model to run, system
    