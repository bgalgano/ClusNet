{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task is to build a convolutional neural network for regression.  Your network will perform the simple task of looking at images of circles and estimating the radius of the circle.  You may find it easier to start with a CNN that classifies the MNIST data (google “mnist keras tutorial” and/or use the hello world model I shared on MARCC) and edit the code to perform the tasks below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.status.idle": "2021-02-24T02:43:53.898718Z",
     "shell.execute_reply": "2021-02-24T02:43:53.897497Z",
     "shell.execute_reply.started": "2021-02-24T02:43:49.940425Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pylab as plt\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib as mpl\n",
    "\n",
    "label_size = 14\n",
    "\n",
    "mpl.rcParams['legend.fontsize'] = label_size\n",
    "mpl.rcParams['axes.labelsize'] = label_size \n",
    "\n",
    "mpl.rcParams['xtick.labelsize'] = label_size\n",
    "mpl.rcParams['ytick.labelsize'] = label_size\n",
    "\n",
    "mpl.rcParams['axes.labelpad'] = 10\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images:  build 1000 images with np.zeros, each image 128x128 pixels in size.   Select a random number (between 10 and 50), and this random number will be a radius.  For every pixel within r of the center, change the value from 0 to 1.  You’ve just made a bunch of images with circles, and the circles vary in radius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-24T02:43:53.900290Z",
     "iopub.status.busy": "2021-02-24T02:43:53.900021Z",
     "iopub.status.idle": "2021-02-24T02:43:53.910447Z",
     "shell.execute_reply": "2021-02-24T02:43:53.909782Z",
     "shell.execute_reply.started": "2021-02-24T02:43:53.900267Z"
    }
   },
   "outputs": [],
   "source": [
    "class Circle:\n",
    "    def __init__(self):    \n",
    "        self.size = 128\n",
    "        self.r = random.randint(10,50)\n",
    "        self.mid_pixel = 64\n",
    "        blank = np.zeros(shape=(self.size,self.size))\n",
    "        idx = np.arange(self.size)\n",
    "\n",
    "        mid_pix = self.size/2\n",
    "        x, y = mid_pix, mid_pix\n",
    "        \n",
    "        self.x = mid_pix\n",
    "        self.y = mid_pix\n",
    "        x_idx, y_idx = np.meshgrid(np.arange(blank.shape[0]), np.arange(blank.shape[1]))\n",
    "\n",
    "        \n",
    "        dist = np.sqrt((x_idx-x)**2+(y_idx-y)**2)\n",
    "        self.dist = dist\n",
    "        blank[np.where(dist<self.r)] = 1\n",
    "        self.image = blank\n",
    "\n",
    "    def plot(self):\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.imshow(self.image,interpolation='none',cmap='binary')\n",
    "        \n",
    "        ticks = np.arange(0,129,32)\n",
    "        plt.xticks(ticks),plt.yticks(ticks)\n",
    "        plt.title(r'$r={}$'.format(self.r))\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "    def shift(self):\n",
    "        \"\"\"\n",
    "        shift cluster randomly within bounds of image\n",
    "        \"\"\"\n",
    "        r = self.r\n",
    "        mid = self.mid_pixel #center pixel index of 384x384 image\n",
    "        delta = self.size - self.mid_pixel - r\n",
    "        x = np.random.randint(low=-1*delta,high=delta,size=1)[0]\n",
    "        y = np.random.randint(low=-1*delta,high=delta,size=1)[0]\n",
    "\n",
    "        self.x += mid\n",
    "        self.y += mid\n",
    "        image_shift = np.roll(self.image,shift=x,axis=0)\n",
    "        self.image = np.roll(image_shift,shift=y,axis=1)\n",
    "        \n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-24T02:43:53.912916Z",
     "iopub.status.busy": "2021-02-24T02:43:53.912618Z",
     "iopub.status.idle": "2021-02-24T02:43:54.351589Z",
     "shell.execute_reply": "2021-02-24T02:43:54.350788Z",
     "shell.execute_reply.started": "2021-02-24T02:43:53.912892Z"
    }
   },
   "outputs": [],
   "source": [
    "# load circle objects into an array\n",
    "cir_set = []\n",
    "for i in range(1000):\n",
    "    cir = Circle()\n",
    "    cir.shift()\n",
    "    cir_set.append(cir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-24T02:43:54.354074Z",
     "iopub.status.busy": "2021-02-24T02:43:54.353878Z",
     "iopub.status.idle": "2021-02-24T02:43:58.217086Z",
     "shell.execute_reply": "2021-02-24T02:43:58.216518Z",
     "shell.execute_reply.started": "2021-02-24T02:43:54.354053Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x648 with 100 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot a sample of 100 circles from our dataset\n",
    "fig, axes = plt.subplots(nrows=10,ncols=10,figsize=(9,9))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    cir = cir_set[i]\n",
    "    ax.imshow(cir.image,interpolation='none',cmap='binary')\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticks([])\n",
    "space= 0.1\n",
    "plt.subplots_adjust(wspace=space,hspace=space)\n",
    "plt.tight_layout()\n",
    "plt.savefig('10x10_rand_circ.png',dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model with the Adam optimizer.\n",
    "\n",
    "Train the model to take the images and output the radius labels.  Train for 250 epochs.\n",
    "\n",
    "Assess the model:  make a scatter plot of true radius vs. predicted radius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-24T02:43:58.218260Z",
     "iopub.status.busy": "2021-02-24T02:43:58.217994Z",
     "iopub.status.idle": "2021-02-24T02:43:58.225070Z",
     "shell.execute_reply": "2021-02-24T02:43:58.222129Z",
     "shell.execute_reply.started": "2021-02-24T02:43:58.218230Z"
    }
   },
   "outputs": [],
   "source": [
    "input_shape = (128,128,1) # width, height, channel number\n",
    "pool_size = (2,2)\n",
    "kernel_size = (3,3)\n",
    "activation = 'relu'\n",
    "strides = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-24T02:43:58.226222Z",
     "iopub.status.busy": "2021-02-24T02:43:58.226056Z",
     "iopub.status.idle": "2021-02-24T02:43:58.300534Z",
     "shell.execute_reply": "2021-02-24T02:43:58.299820Z",
     "shell.execute_reply.started": "2021-02-24T02:43:58.226202Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 123, 123, 16)      592       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 61, 61, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 59, 59, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 29, 29, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 27, 27, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 200)               13000     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                2020      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 58,869\n",
      "Trainable params: 58,869\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(128,128,1)),\n",
    "        \n",
    "        # 1. 3×3 convolution with 16 filters\n",
    "        layers.Conv2D(filters=16, kernel_size=(6,6), activation=activation),\n",
    "\n",
    "        # 2. 2×2, stride-2 max pooling\n",
    "        layers.MaxPooling2D(pool_size=pool_size, strides=strides),\n",
    "\n",
    "        # 3. 3×3 convolution with 32 filters\n",
    "        layers.Conv2D(filters=32, kernel_size=kernel_size, activation=activation),\n",
    "\n",
    "        # 4. 2×2, stride-2 max pooling\n",
    "        layers.MaxPooling2D(pool_size=pool_size, strides=strides),\n",
    "\n",
    "        # 5. 3×3 convolution with 64 filters\n",
    "        layers.Conv2D(filters=64, kernel_size=kernel_size, activation=activation),\n",
    "\n",
    "        # 6. 2×2, stride-2 max pooling\n",
    "        layers.MaxPooling2D(pool_size=pool_size, strides=strides),\n",
    "\n",
    "        # 7. global average pooling\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "\n",
    "        # 8. 10% dropout\n",
    "        layers.Dropout(0.1),\n",
    "\n",
    "        # 9. 200 neurons, fully connected\n",
    "        layers.Dense(units=200),\n",
    "\n",
    "        # 10. 10% dropout\n",
    "        layers.Dropout(0.1),\n",
    "\n",
    "        # 11. 100 neurons, fully connected\n",
    "        layers.Dense(units=100),\n",
    "\n",
    "        # 12. 20 neurons, fully connected\n",
    "        layers.Dense(units=20),\n",
    "\n",
    "        # 13. output neuron\n",
    "        layers.Dense(units=1)\n",
    "\n",
    "    ]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(14,14,64)\n",
    "probing length scales that are 128/14\n",
    "9 pixel lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-24T02:43:58.301749Z",
     "iopub.status.busy": "2021-02-24T02:43:58.301431Z",
     "iopub.status.idle": "2021-02-24T02:43:58.454540Z",
     "shell.execute_reply": "2021-02-24T02:43:58.453805Z",
     "shell.execute_reply.started": "2021-02-24T02:43:58.301727Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "# fit the keras model on the dataset\n",
    "data = np.array([cir.image for cir in cir_set])\n",
    "labels = np.array([cir.r for cir in cir_set])\n",
    "\n",
    "idx = np.arange(0,1000,1)\n",
    "test_idx = random.sample(list(idx),k=100)\n",
    "train_idx = np.delete(idx, test_idx)\n",
    "\n",
    "x_train, y_train = data[train_idx], labels[train_idx]\n",
    "x_train = x_train.reshape(-1, 128, 128, 1)\n",
    "x_test, y_test = data[test_idx], labels[test_idx]\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-24T02:43:58.455930Z",
     "iopub.status.busy": "2021-02-24T02:43:58.455522Z",
     "iopub.status.idle": "2021-02-24T03:32:02.523242Z",
     "shell.execute_reply": "2021-02-24T03:32:02.522535Z",
     "shell.execute_reply.started": "2021-02-24T02:43:58.455899Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "7/7 [==============================] - 5s 682ms/step - loss: 989.1756 - accuracy: 0.0000e+00 - val_loss: 924.4681 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/250\n",
      "7/7 [==============================] - 4s 596ms/step - loss: 919.7659 - accuracy: 0.0000e+00 - val_loss: 720.2532 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/250\n",
      "7/7 [==============================] - 5s 643ms/step - loss: 636.4149 - accuracy: 0.0000e+00 - val_loss: 113.6899 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/250\n",
      "7/7 [==============================] - 4s 600ms/step - loss: 92.4062 - accuracy: 0.0000e+00 - val_loss: 87.1625 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/250\n",
      "7/7 [==============================] - 5s 642ms/step - loss: 59.4569 - accuracy: 0.0000e+00 - val_loss: 56.8208 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/250\n",
      "7/7 [==============================] - 4s 624ms/step - loss: 63.5237 - accuracy: 0.0000e+00 - val_loss: 13.9643 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/250\n",
      "7/7 [==============================] - 4s 617ms/step - loss: 22.5448 - accuracy: 0.0000e+00 - val_loss: 22.1473 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/250\n",
      "7/7 [==============================] - 4s 598ms/step - loss: 20.0139 - accuracy: 0.0000e+00 - val_loss: 12.9128 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/250\n",
      "7/7 [==============================] - 4s 603ms/step - loss: 19.1294 - accuracy: 0.0000e+00 - val_loss: 8.0282 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/250\n",
      "7/7 [==============================] - 4s 602ms/step - loss: 15.5994 - accuracy: 0.0000e+00 - val_loss: 9.3102 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/250\n",
      "7/7 [==============================] - 4s 600ms/step - loss: 13.8597 - accuracy: 0.0000e+00 - val_loss: 7.2152 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/250\n",
      "7/7 [==============================] - 4s 595ms/step - loss: 12.5871 - accuracy: 0.0000e+00 - val_loss: 5.5221 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/250\n",
      "7/7 [==============================] - 5s 639ms/step - loss: 11.4981 - accuracy: 0.0000e+00 - val_loss: 4.9179 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/250\n",
      "7/7 [==============================] - 5s 640ms/step - loss: 10.8967 - accuracy: 0.0000e+00 - val_loss: 4.5194 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/250\n",
      "7/7 [==============================] - 4s 641ms/step - loss: 11.1140 - accuracy: 0.0000e+00 - val_loss: 4.2789 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/250\n",
      "7/7 [==============================] - 5s 640ms/step - loss: 11.3727 - accuracy: 0.0000e+00 - val_loss: 4.1761 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/250\n",
      "7/7 [==============================] - 4s 624ms/step - loss: 8.5553 - accuracy: 0.0000e+00 - val_loss: 4.3198 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/250\n",
      "7/7 [==============================] - 4s 609ms/step - loss: 8.4635 - accuracy: 0.0000e+00 - val_loss: 4.1484 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/250\n",
      "7/7 [==============================] - 5s 632ms/step - loss: 9.9412 - accuracy: 0.0000e+00 - val_loss: 4.1927 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/250\n",
      "7/7 [==============================] - 4s 621ms/step - loss: 9.9902 - accuracy: 0.0000e+00 - val_loss: 4.1851 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/250\n",
      "7/7 [==============================] - 4s 633ms/step - loss: 9.0178 - accuracy: 0.0000e+00 - val_loss: 4.4759 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/250\n",
      "7/7 [==============================] - 4s 633ms/step - loss: 9.6062 - accuracy: 0.0000e+00 - val_loss: 4.1986 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/250\n",
      "7/7 [==============================] - 4s 596ms/step - loss: 8.6372 - accuracy: 0.0000e+00 - val_loss: 4.2329 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/250\n",
      "7/7 [==============================] - 4s 589ms/step - loss: 8.8525 - accuracy: 0.0000e+00 - val_loss: 4.1497 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/250\n",
      "7/7 [==============================] - 4s 603ms/step - loss: 9.2499 - accuracy: 0.0000e+00 - val_loss: 4.3374 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/250\n",
      "7/7 [==============================] - 4s 614ms/step - loss: 9.9479 - accuracy: 0.0000e+00 - val_loss: 4.1215 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/250\n",
      "7/7 [==============================] - 4s 597ms/step - loss: 9.0176 - accuracy: 0.0000e+00 - val_loss: 4.2722 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/250\n",
      "7/7 [==============================] - 4s 608ms/step - loss: 9.3554 - accuracy: 0.0000e+00 - val_loss: 4.1359 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/250\n",
      "7/7 [==============================] - 4s 614ms/step - loss: 9.3999 - accuracy: 0.0000e+00 - val_loss: 4.1785 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/250\n",
      "7/7 [==============================] - 4s 612ms/step - loss: 9.6373 - accuracy: 0.0000e+00 - val_loss: 4.0950 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/250\n",
      "7/7 [==============================] - 4s 602ms/step - loss: 10.3819 - accuracy: 0.0000e+00 - val_loss: 4.0974 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/250\n",
      "7/7 [==============================] - 4s 609ms/step - loss: 8.8985 - accuracy: 0.0000e+00 - val_loss: 4.2025 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/250\n",
      "7/7 [==============================] - 4s 600ms/step - loss: 8.4803 - accuracy: 0.0000e+00 - val_loss: 4.0979 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/250\n",
      "7/7 [==============================] - 4s 594ms/step - loss: 9.3375 - accuracy: 0.0000e+00 - val_loss: 4.1187 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/250\n",
      "7/7 [==============================] - 4s 631ms/step - loss: 8.3260 - accuracy: 0.0000e+00 - val_loss: 4.0381 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/250\n",
      "7/7 [==============================] - 4s 610ms/step - loss: 8.5341 - accuracy: 0.0000e+00 - val_loss: 4.2273 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/250\n",
      "7/7 [==============================] - 4s 617ms/step - loss: 8.3466 - accuracy: 0.0000e+00 - val_loss: 4.0192 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/250\n",
      "7/7 [==============================] - 4s 606ms/step - loss: 9.1470 - accuracy: 0.0000e+00 - val_loss: 4.2342 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/250\n",
      "7/7 [==============================] - 4s 612ms/step - loss: 8.5486 - accuracy: 0.0000e+00 - val_loss: 4.0201 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/250\n",
      "7/7 [==============================] - 4s 598ms/step - loss: 8.3366 - accuracy: 0.0000e+00 - val_loss: 4.0624 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/250\n",
      "7/7 [==============================] - 4s 592ms/step - loss: 8.7993 - accuracy: 0.0000e+00 - val_loss: 4.0474 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/250\n",
      "7/7 [==============================] - 4s 592ms/step - loss: 8.7575 - accuracy: 0.0000e+00 - val_loss: 4.0971 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/250\n",
      "7/7 [==============================] - 4s 586ms/step - loss: 8.9463 - accuracy: 0.0000e+00 - val_loss: 4.3627 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/250\n",
      "7/7 [==============================] - 4s 599ms/step - loss: 8.9460 - accuracy: 0.0000e+00 - val_loss: 4.0124 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/250\n",
      "7/7 [==============================] - 4s 599ms/step - loss: 8.4060 - accuracy: 0.0000e+00 - val_loss: 4.3463 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/250\n",
      "7/7 [==============================] - 4s 613ms/step - loss: 8.3824 - accuracy: 0.0000e+00 - val_loss: 4.0035 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/250\n",
      "7/7 [==============================] - 4s 612ms/step - loss: 9.4890 - accuracy: 0.0000e+00 - val_loss: 4.1453 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/250\n",
      "7/7 [==============================] - 4s 606ms/step - loss: 8.0767 - accuracy: 0.0000e+00 - val_loss: 3.9977 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/250\n",
      "7/7 [==============================] - 4s 630ms/step - loss: 9.0999 - accuracy: 0.0000e+00 - val_loss: 4.1216 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/250\n",
      "7/7 [==============================] - 4s 632ms/step - loss: 8.5230 - accuracy: 0.0000e+00 - val_loss: 4.2502 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/250\n",
      "7/7 [==============================] - 4s 625ms/step - loss: 8.4895 - accuracy: 0.0000e+00 - val_loss: 4.0281 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/250\n",
      "7/7 [==============================] - 4s 601ms/step - loss: 8.9324 - accuracy: 0.0000e+00 - val_loss: 4.1201 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/250\n",
      "7/7 [==============================] - 4s 591ms/step - loss: 8.1311 - accuracy: 0.0000e+00 - val_loss: 3.9921 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/250\n",
      "7/7 [==============================] - 4s 590ms/step - loss: 8.4780 - accuracy: 0.0000e+00 - val_loss: 3.9576 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/250\n",
      "7/7 [==============================] - 4s 597ms/step - loss: 8.1599 - accuracy: 0.0000e+00 - val_loss: 3.9975 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/250\n",
      "7/7 [==============================] - 4s 596ms/step - loss: 8.3331 - accuracy: 0.0000e+00 - val_loss: 4.1066 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/250\n",
      "7/7 [==============================] - 4s 594ms/step - loss: 9.0203 - accuracy: 0.0000e+00 - val_loss: 3.9419 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/250\n",
      "7/7 [==============================] - 4s 589ms/step - loss: 9.0220 - accuracy: 0.0000e+00 - val_loss: 4.8555 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/250\n",
      "7/7 [==============================] - 4s 595ms/step - loss: 9.0170 - accuracy: 0.0000e+00 - val_loss: 4.1532 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/250\n",
      "7/7 [==============================] - 4s 606ms/step - loss: 8.4272 - accuracy: 0.0000e+00 - val_loss: 4.4203 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/250\n",
      "7/7 [==============================] - 4s 609ms/step - loss: 10.1312 - accuracy: 0.0000e+00 - val_loss: 4.0045 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/250\n",
      "7/7 [==============================] - 4s 599ms/step - loss: 9.0593 - accuracy: 0.0000e+00 - val_loss: 4.0188 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/250\n",
      "7/7 [==============================] - 4s 596ms/step - loss: 8.2967 - accuracy: 0.0000e+00 - val_loss: 4.1981 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/250\n",
      "7/7 [==============================] - 4s 592ms/step - loss: 8.5734 - accuracy: 0.0000e+00 - val_loss: 4.0372 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/250\n",
      "7/7 [==============================] - 4s 632ms/step - loss: 8.1431 - accuracy: 0.0000e+00 - val_loss: 4.8624 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/250\n",
      "7/7 [==============================] - 4s 606ms/step - loss: 9.1315 - accuracy: 0.0000e+00 - val_loss: 3.9312 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/250\n",
      "7/7 [==============================] - 4s 593ms/step - loss: 9.3584 - accuracy: 0.0000e+00 - val_loss: 4.0951 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/250\n",
      "7/7 [==============================] - 4s 616ms/step - loss: 8.8787 - accuracy: 0.0000e+00 - val_loss: 4.2904 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/250\n",
      "7/7 [==============================] - 4s 621ms/step - loss: 9.1801 - accuracy: 0.0000e+00 - val_loss: 3.9494 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/250\n",
      "7/7 [==============================] - 4s 625ms/step - loss: 8.3476 - accuracy: 0.0000e+00 - val_loss: 3.9467 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/250\n",
      "7/7 [==============================] - 4s 632ms/step - loss: 8.3748 - accuracy: 0.0000e+00 - val_loss: 4.1971 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/250\n",
      "7/7 [==============================] - 4s 631ms/step - loss: 8.9517 - accuracy: 0.0000e+00 - val_loss: 3.9912 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/250\n",
      "7/7 [==============================] - 4s 624ms/step - loss: 8.1259 - accuracy: 0.0000e+00 - val_loss: 3.9416 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/250\n",
      "7/7 [==============================] - 4s 622ms/step - loss: 7.7477 - accuracy: 0.0000e+00 - val_loss: 3.9156 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/250\n",
      "7/7 [==============================] - 4s 603ms/step - loss: 7.9420 - accuracy: 0.0000e+00 - val_loss: 3.9610 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/250\n",
      "7/7 [==============================] - 4s 611ms/step - loss: 8.1303 - accuracy: 0.0000e+00 - val_loss: 3.9008 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/250\n",
      "7/7 [==============================] - 4s 610ms/step - loss: 7.8026 - accuracy: 0.0000e+00 - val_loss: 3.9203 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/250\n",
      "7/7 [==============================] - 4s 600ms/step - loss: 8.3922 - accuracy: 0.0000e+00 - val_loss: 3.8852 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/250\n",
      "7/7 [==============================] - 4s 601ms/step - loss: 7.4231 - accuracy: 0.0000e+00 - val_loss: 3.9077 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/250\n",
      "7/7 [==============================] - 4s 617ms/step - loss: 7.6561 - accuracy: 0.0000e+00 - val_loss: 3.9186 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/250\n",
      "7/7 [==============================] - 4s 610ms/step - loss: 8.0732 - accuracy: 0.0000e+00 - val_loss: 3.8961 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/250\n",
      "7/7 [==============================] - 4s 620ms/step - loss: 7.9855 - accuracy: 0.0000e+00 - val_loss: 4.1835 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/250\n",
      "7/7 [==============================] - 4s 605ms/step - loss: 8.0439 - accuracy: 0.0000e+00 - val_loss: 3.9010 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/250\n",
      "7/7 [==============================] - 4s 616ms/step - loss: 7.3550 - accuracy: 0.0000e+00 - val_loss: 3.9333 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/250\n",
      "7/7 [==============================] - 4s 608ms/step - loss: 7.4764 - accuracy: 0.0000e+00 - val_loss: 4.4613 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/250\n",
      "7/7 [==============================] - 4s 620ms/step - loss: 7.6302 - accuracy: 0.0000e+00 - val_loss: 4.0698 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/250\n",
      "7/7 [==============================] - 4s 609ms/step - loss: 7.6669 - accuracy: 0.0000e+00 - val_loss: 3.9117 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/250\n",
      "7/7 [==============================] - 4s 618ms/step - loss: 8.3821 - accuracy: 0.0000e+00 - val_loss: 4.3013 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/250\n",
      "7/7 [==============================] - 4s 613ms/step - loss: 8.3963 - accuracy: 0.0000e+00 - val_loss: 4.1511 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/250\n",
      "7/7 [==============================] - 4s 612ms/step - loss: 8.3900 - accuracy: 0.0000e+00 - val_loss: 5.8912 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/250\n",
      "7/7 [==============================] - 4s 621ms/step - loss: 10.1799 - accuracy: 0.0000e+00 - val_loss: 4.8606 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/250\n",
      "7/7 [==============================] - 5s 658ms/step - loss: 8.9530 - accuracy: 0.0000e+00 - val_loss: 3.9543 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/250\n",
      "7/7 [==============================] - 4s 621ms/step - loss: 8.5426 - accuracy: 0.0000e+00 - val_loss: 3.8980 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/250\n",
      "7/7 [==============================] - 4s 598ms/step - loss: 7.9320 - accuracy: 0.0000e+00 - val_loss: 3.8922 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/250\n",
      "7/7 [==============================] - 4s 626ms/step - loss: 8.2783 - accuracy: 0.0000e+00 - val_loss: 3.8916 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/250\n",
      "7/7 [==============================] - 4s 594ms/step - loss: 8.0694 - accuracy: 0.0000e+00 - val_loss: 3.9970 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/250\n",
      "7/7 [==============================] - 4s 605ms/step - loss: 7.9427 - accuracy: 0.0000e+00 - val_loss: 3.9091 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/250\n",
      "7/7 [==============================] - 4s 598ms/step - loss: 7.3783 - accuracy: 0.0000e+00 - val_loss: 3.9178 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/250\n",
      "7/7 [==============================] - 4s 630ms/step - loss: 7.9933 - accuracy: 0.0000e+00 - val_loss: 4.2602 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/250\n",
      "7/7 [==============================] - 5s 654ms/step - loss: 9.2186 - accuracy: 0.0000e+00 - val_loss: 4.6080 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/250\n",
      "7/7 [==============================] - 5s 639ms/step - loss: 8.8435 - accuracy: 0.0000e+00 - val_loss: 4.0754 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/250\n",
      "7/7 [==============================] - 4s 604ms/step - loss: 7.2690 - accuracy: 0.0000e+00 - val_loss: 3.9426 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/250\n",
      "7/7 [==============================] - 4s 593ms/step - loss: 7.7081 - accuracy: 0.0000e+00 - val_loss: 4.0182 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/250\n",
      "7/7 [==============================] - 4s 599ms/step - loss: 7.5566 - accuracy: 0.0000e+00 - val_loss: 3.8885 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/250\n",
      "7/7 [==============================] - 4s 592ms/step - loss: 8.5082 - accuracy: 0.0000e+00 - val_loss: 3.9038 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/250\n",
      "7/7 [==============================] - 4s 595ms/step - loss: 7.8411 - accuracy: 0.0000e+00 - val_loss: 4.0651 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/250\n",
      "7/7 [==============================] - 4s 624ms/step - loss: 7.4919 - accuracy: 0.0000e+00 - val_loss: 3.9646 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/250\n",
      "7/7 [==============================] - 4s 594ms/step - loss: 7.7046 - accuracy: 0.0000e+00 - val_loss: 3.7905 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/250\n",
      "7/7 [==============================] - 4s 597ms/step - loss: 7.6486 - accuracy: 0.0000e+00 - val_loss: 4.3870 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/250\n",
      "7/7 [==============================] - 4s 601ms/step - loss: 8.1029 - accuracy: 0.0000e+00 - val_loss: 4.3965 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/250\n",
      "7/7 [==============================] - 4s 598ms/step - loss: 7.8488 - accuracy: 0.0000e+00 - val_loss: 3.9077 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/250\n",
      "7/7 [==============================] - 4s 612ms/step - loss: 7.3429 - accuracy: 0.0000e+00 - val_loss: 3.8120 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/250\n",
      "7/7 [==============================] - 5s 635ms/step - loss: 9.0970 - accuracy: 0.0000e+00 - val_loss: 3.9668 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/250\n",
      "7/7 [==============================] - 5s 658ms/step - loss: 7.2523 - accuracy: 0.0000e+00 - val_loss: 3.9299 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/250\n",
      "7/7 [==============================] - 4s 601ms/step - loss: 7.2957 - accuracy: 0.0000e+00 - val_loss: 3.7481 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/250\n",
      "7/7 [==============================] - 4s 596ms/step - loss: 7.8447 - accuracy: 0.0000e+00 - val_loss: 3.7257 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/250\n",
      "7/7 [==============================] - 4s 593ms/step - loss: 7.4378 - accuracy: 0.0000e+00 - val_loss: 4.3044 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/250\n",
      "7/7 [==============================] - 4s 636ms/step - loss: 7.5828 - accuracy: 0.0000e+00 - val_loss: 3.7290 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/250\n",
      "7/7 [==============================] - 4s 614ms/step - loss: 7.2602 - accuracy: 0.0000e+00 - val_loss: 3.8774 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/250\n",
      "7/7 [==============================] - 4s 597ms/step - loss: 7.5944 - accuracy: 0.0000e+00 - val_loss: 3.7202 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/250\n",
      "7/7 [==============================] - 4s 596ms/step - loss: 7.3302 - accuracy: 0.0000e+00 - val_loss: 4.8278 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/250\n",
      "7/7 [==============================] - 5s 648ms/step - loss: 8.1222 - accuracy: 0.0000e+00 - val_loss: 3.7764 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/250\n",
      "7/7 [==============================] - 4s 606ms/step - loss: 6.8939 - accuracy: 0.0000e+00 - val_loss: 4.0490 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/250\n",
      "7/7 [==============================] - 4s 610ms/step - loss: 7.9246 - accuracy: 0.0000e+00 - val_loss: 5.6588 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/250\n",
      "7/7 [==============================] - 4s 619ms/step - loss: 8.9152 - accuracy: 0.0000e+00 - val_loss: 3.8393 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/250\n",
      "7/7 [==============================] - 4s 598ms/step - loss: 8.6168 - accuracy: 0.0000e+00 - val_loss: 4.5106 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/250\n",
      "7/7 [==============================] - 4s 594ms/step - loss: 8.3644 - accuracy: 0.0000e+00 - val_loss: 4.5852 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/250\n",
      "7/7 [==============================] - 4s 601ms/step - loss: 8.8530 - accuracy: 0.0000e+00 - val_loss: 3.8008 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/250\n",
      "7/7 [==============================] - 4s 594ms/step - loss: 7.4200 - accuracy: 0.0000e+00 - val_loss: 3.7103 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/250\n",
      "7/7 [==============================] - 4s 596ms/step - loss: 7.0308 - accuracy: 0.0000e+00 - val_loss: 4.3970 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/250\n",
      "7/7 [==============================] - 4s 593ms/step - loss: 7.4057 - accuracy: 0.0000e+00 - val_loss: 3.8278 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/250\n",
      "7/7 [==============================] - 4s 593ms/step - loss: 8.6363 - accuracy: 0.0000e+00 - val_loss: 3.7851 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/250\n",
      "7/7 [==============================] - 5s 656ms/step - loss: 7.3109 - accuracy: 0.0000e+00 - val_loss: 4.0041 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/250\n",
      "7/7 [==============================] - 4s 602ms/step - loss: 7.4342 - accuracy: 0.0000e+00 - val_loss: 3.7989 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/250\n",
      "7/7 [==============================] - 4s 584ms/step - loss: 7.6467 - accuracy: 0.0000e+00 - val_loss: 3.8986 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/250\n",
      "7/7 [==============================] - 4s 607ms/step - loss: 7.7349 - accuracy: 0.0000e+00 - val_loss: 3.7842 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/250\n",
      "7/7 [==============================] - 4s 591ms/step - loss: 7.5051 - accuracy: 0.0000e+00 - val_loss: 3.6956 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/250\n",
      "7/7 [==============================] - 4s 579ms/step - loss: 7.8933 - accuracy: 0.0000e+00 - val_loss: 4.0082 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/250\n",
      "7/7 [==============================] - 4s 583ms/step - loss: 7.6865 - accuracy: 0.0000e+00 - val_loss: 3.7200 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/250\n",
      "7/7 [==============================] - 4s 582ms/step - loss: 7.8589 - accuracy: 0.0000e+00 - val_loss: 3.7152 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/250\n",
      "7/7 [==============================] - 4s 587ms/step - loss: 7.7755 - accuracy: 0.0000e+00 - val_loss: 3.9778 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/250\n",
      "7/7 [==============================] - 4s 583ms/step - loss: 7.5992 - accuracy: 0.0000e+00 - val_loss: 3.7417 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/250\n",
      "7/7 [==============================] - 4s 572ms/step - loss: 7.6251 - accuracy: 0.0000e+00 - val_loss: 3.7214 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/250\n",
      "7/7 [==============================] - 4s 579ms/step - loss: 7.7089 - accuracy: 0.0000e+00 - val_loss: 4.0751 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/250\n",
      "7/7 [==============================] - 4s 592ms/step - loss: 7.2449 - accuracy: 0.0000e+00 - val_loss: 3.7111 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/250\n",
      "7/7 [==============================] - 4s 582ms/step - loss: 7.0954 - accuracy: 0.0000e+00 - val_loss: 3.7435 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/250\n",
      "7/7 [==============================] - 563s 94s/step - loss: 7.5113 - accuracy: 0.0000e+00 - val_loss: 3.8346 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/250\n",
      "7/7 [==============================] - 12s 2s/step - loss: 7.0448 - accuracy: 0.0000e+00 - val_loss: 3.9500 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/250\n",
      "7/7 [==============================] - 4s 605ms/step - loss: 7.9244 - accuracy: 0.0000e+00 - val_loss: 3.7446 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/250\n",
      "7/7 [==============================] - 4s 579ms/step - loss: 6.6847 - accuracy: 0.0000e+00 - val_loss: 3.8983 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/250\n",
      "7/7 [==============================] - 4s 574ms/step - loss: 6.8582 - accuracy: 0.0000e+00 - val_loss: 3.7420 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/250\n",
      "7/7 [==============================] - 5s 666ms/step - loss: 7.0179 - accuracy: 0.0000e+00 - val_loss: 4.0064 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/250\n",
      "7/7 [==============================] - 4s 574ms/step - loss: 7.1895 - accuracy: 0.0000e+00 - val_loss: 3.9042 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/250\n",
      "7/7 [==============================] - 4s 583ms/step - loss: 7.1816 - accuracy: 0.0000e+00 - val_loss: 3.6895 - val_accuracy: 0.0000e+00\n",
      "Epoch 155/250\n",
      "7/7 [==============================] - 4s 575ms/step - loss: 6.9545 - accuracy: 0.0000e+00 - val_loss: 3.6961 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/250\n",
      "7/7 [==============================] - 4s 570ms/step - loss: 7.2141 - accuracy: 0.0000e+00 - val_loss: 3.8223 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/250\n",
      "7/7 [==============================] - 4s 567ms/step - loss: 7.1397 - accuracy: 0.0000e+00 - val_loss: 4.1334 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/250\n",
      "7/7 [==============================] - 4s 574ms/step - loss: 7.9440 - accuracy: 0.0000e+00 - val_loss: 3.7010 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/250\n",
      "7/7 [==============================] - 4s 575ms/step - loss: 6.9591 - accuracy: 0.0000e+00 - val_loss: 4.1693 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/250\n",
      "7/7 [==============================] - 4s 578ms/step - loss: 7.5819 - accuracy: 0.0000e+00 - val_loss: 3.7248 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/250\n",
      "7/7 [==============================] - 4s 569ms/step - loss: 8.2570 - accuracy: 0.0000e+00 - val_loss: 3.7027 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/250\n",
      "7/7 [==============================] - 4s 573ms/step - loss: 7.6470 - accuracy: 0.0000e+00 - val_loss: 3.9118 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/250\n",
      "7/7 [==============================] - 4s 573ms/step - loss: 7.7157 - accuracy: 0.0000e+00 - val_loss: 3.7488 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/250\n",
      "7/7 [==============================] - 4s 573ms/step - loss: 7.8642 - accuracy: 0.0000e+00 - val_loss: 3.7899 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/250\n",
      "7/7 [==============================] - 4s 572ms/step - loss: 7.3530 - accuracy: 0.0000e+00 - val_loss: 4.2110 - val_accuracy: 0.0000e+00\n",
      "Epoch 166/250\n",
      "7/7 [==============================] - 562s 94s/step - loss: 7.9094 - accuracy: 0.0000e+00 - val_loss: 4.3130 - val_accuracy: 0.0000e+00\n",
      "Epoch 167/250\n",
      "7/7 [==============================] - 5s 739ms/step - loss: 7.9689 - accuracy: 0.0000e+00 - val_loss: 3.8978 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/250\n",
      "7/7 [==============================] - 4s 587ms/step - loss: 8.1098 - accuracy: 0.0000e+00 - val_loss: 3.8329 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/250\n",
      "7/7 [==============================] - 6s 642ms/step - loss: 7.6126 - accuracy: 0.0000e+00 - val_loss: 5.1365 - val_accuracy: 0.0000e+00\n",
      "Epoch 170/250\n",
      "7/7 [==============================] - 4s 599ms/step - loss: 9.0352 - accuracy: 0.0000e+00 - val_loss: 4.0382 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/250\n",
      "7/7 [==============================] - 4s 596ms/step - loss: 7.9754 - accuracy: 0.0000e+00 - val_loss: 4.0963 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/250\n",
      "7/7 [==============================] - 4s 553ms/step - loss: 7.0302 - accuracy: 0.0000e+00 - val_loss: 4.4120 - val_accuracy: 0.0000e+00\n",
      "Epoch 173/250\n",
      "7/7 [==============================] - 4s 552ms/step - loss: 8.4607 - accuracy: 0.0000e+00 - val_loss: 3.7002 - val_accuracy: 0.0000e+00\n",
      "Epoch 174/250\n",
      "7/7 [==============================] - 4s 551ms/step - loss: 7.3765 - accuracy: 0.0000e+00 - val_loss: 4.5015 - val_accuracy: 0.0000e+00\n",
      "Epoch 175/250\n",
      "7/7 [==============================] - 4s 585ms/step - loss: 7.7258 - accuracy: 0.0000e+00 - val_loss: 3.6407 - val_accuracy: 0.0000e+00\n",
      "Epoch 176/250\n",
      "7/7 [==============================] - 4s 616ms/step - loss: 7.7378 - accuracy: 0.0000e+00 - val_loss: 4.1635 - val_accuracy: 0.0000e+00\n",
      "Epoch 177/250\n",
      "7/7 [==============================] - 4s 559ms/step - loss: 7.4691 - accuracy: 0.0000e+00 - val_loss: 4.1651 - val_accuracy: 0.0000e+00\n",
      "Epoch 178/250\n",
      "7/7 [==============================] - 564s 94s/step - loss: 7.4859 - accuracy: 0.0000e+00 - val_loss: 3.6060 - val_accuracy: 0.0000e+00\n",
      "Epoch 179/250\n",
      "7/7 [==============================] - 5s 620ms/step - loss: 7.1781 - accuracy: 0.0000e+00 - val_loss: 3.6165 - val_accuracy: 0.0000e+00\n",
      "Epoch 180/250\n",
      "7/7 [==============================] - 5s 655ms/step - loss: 7.6804 - accuracy: 0.0000e+00 - val_loss: 3.6137 - val_accuracy: 0.0000e+00\n",
      "Epoch 181/250\n",
      "7/7 [==============================] - 13s 2s/step - loss: 6.8457 - accuracy: 0.0000e+00 - val_loss: 3.8207 - val_accuracy: 0.0000e+00\n",
      "Epoch 182/250\n",
      "7/7 [==============================] - 14s 2s/step - loss: 8.2436 - accuracy: 0.0000e+00 - val_loss: 3.6763 - val_accuracy: 0.0000e+00\n",
      "Epoch 183/250\n",
      "7/7 [==============================] - 14s 2s/step - loss: 7.8395 - accuracy: 0.0000e+00 - val_loss: 3.7086 - val_accuracy: 0.0000e+00\n",
      "Epoch 184/250\n",
      "7/7 [==============================] - 14s 2s/step - loss: 7.1276 - accuracy: 0.0000e+00 - val_loss: 3.7627 - val_accuracy: 0.0000e+00\n",
      "Epoch 185/250\n",
      "7/7 [==============================] - 90s 15s/step - loss: 6.8600 - accuracy: 0.0000e+00 - val_loss: 3.6133 - val_accuracy: 0.0000e+00\n",
      "Epoch 186/250\n",
      "7/7 [==============================] - 6s 738ms/step - loss: 6.9924 - accuracy: 0.0000e+00 - val_loss: 3.6095 - val_accuracy: 0.0000e+00\n",
      "Epoch 187/250\n",
      "7/7 [==============================] - 4s 592ms/step - loss: 7.6081 - accuracy: 0.0000e+00 - val_loss: 3.5977 - val_accuracy: 0.0000e+00\n",
      "Epoch 188/250\n",
      "7/7 [==============================] - 4s 582ms/step - loss: 7.0439 - accuracy: 0.0000e+00 - val_loss: 3.7366 - val_accuracy: 0.0000e+00\n",
      "Epoch 189/250\n",
      "7/7 [==============================] - 4s 571ms/step - loss: 7.6717 - accuracy: 0.0000e+00 - val_loss: 4.1625 - val_accuracy: 0.0000e+00\n",
      "Epoch 190/250\n",
      "7/7 [==============================] - 4s 574ms/step - loss: 7.8748 - accuracy: 0.0000e+00 - val_loss: 5.1282 - val_accuracy: 0.0000e+00\n",
      "Epoch 191/250\n",
      "7/7 [==============================] - 4s 625ms/step - loss: 8.2402 - accuracy: 0.0000e+00 - val_loss: 3.6273 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/250\n",
      "7/7 [==============================] - 5s 669ms/step - loss: 6.8881 - accuracy: 0.0000e+00 - val_loss: 3.5774 - val_accuracy: 0.0000e+00\n",
      "Epoch 193/250\n",
      "7/7 [==============================] - 5s 661ms/step - loss: 6.8795 - accuracy: 0.0000e+00 - val_loss: 3.8350 - val_accuracy: 0.0000e+00\n",
      "Epoch 194/250\n",
      "7/7 [==============================] - 4s 574ms/step - loss: 6.8284 - accuracy: 0.0000e+00 - val_loss: 3.6099 - val_accuracy: 0.0000e+00\n",
      "Epoch 195/250\n",
      "7/7 [==============================] - 4s 568ms/step - loss: 7.2297 - accuracy: 0.0000e+00 - val_loss: 3.6816 - val_accuracy: 0.0000e+00\n",
      "Epoch 196/250\n",
      "7/7 [==============================] - 4s 620ms/step - loss: 7.1262 - accuracy: 0.0000e+00 - val_loss: 4.4402 - val_accuracy: 0.0000e+00\n",
      "Epoch 197/250\n",
      "7/7 [==============================] - 4s 579ms/step - loss: 7.4610 - accuracy: 0.0000e+00 - val_loss: 4.1123 - val_accuracy: 0.0000e+00\n",
      "Epoch 198/250\n",
      "7/7 [==============================] - 4s 597ms/step - loss: 8.2208 - accuracy: 0.0000e+00 - val_loss: 3.5965 - val_accuracy: 0.0000e+00\n",
      "Epoch 199/250\n",
      "7/7 [==============================] - 5s 644ms/step - loss: 7.3751 - accuracy: 0.0000e+00 - val_loss: 3.6258 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/250\n",
      "7/7 [==============================] - 4s 614ms/step - loss: 7.1593 - accuracy: 0.0000e+00 - val_loss: 3.8036 - val_accuracy: 0.0000e+00\n",
      "Epoch 201/250\n",
      "7/7 [==============================] - 4s 610ms/step - loss: 7.5738 - accuracy: 0.0000e+00 - val_loss: 3.7735 - val_accuracy: 0.0000e+00\n",
      "Epoch 202/250\n",
      "7/7 [==============================] - 4s 574ms/step - loss: 7.1370 - accuracy: 0.0000e+00 - val_loss: 3.6185 - val_accuracy: 0.0000e+00\n",
      "Epoch 203/250\n",
      "7/7 [==============================] - 4s 573ms/step - loss: 6.6502 - accuracy: 0.0000e+00 - val_loss: 4.3470 - val_accuracy: 0.0000e+00\n",
      "Epoch 204/250\n",
      "7/7 [==============================] - 4s 566ms/step - loss: 7.2351 - accuracy: 0.0000e+00 - val_loss: 4.0060 - val_accuracy: 0.0000e+00\n",
      "Epoch 205/250\n",
      "7/7 [==============================] - 4s 572ms/step - loss: 7.4687 - accuracy: 0.0000e+00 - val_loss: 3.6091 - val_accuracy: 0.0000e+00\n",
      "Epoch 206/250\n",
      "7/7 [==============================] - 4s 580ms/step - loss: 7.1925 - accuracy: 0.0000e+00 - val_loss: 3.5808 - val_accuracy: 0.0000e+00\n",
      "Epoch 207/250\n",
      "7/7 [==============================] - 4s 591ms/step - loss: 6.7613 - accuracy: 0.0000e+00 - val_loss: 3.7699 - val_accuracy: 0.0000e+00\n",
      "Epoch 208/250\n",
      "7/7 [==============================] - 4s 585ms/step - loss: 7.4527 - accuracy: 0.0000e+00 - val_loss: 3.6689 - val_accuracy: 0.0000e+00\n",
      "Epoch 209/250\n",
      "7/7 [==============================] - 4s 609ms/step - loss: 6.9879 - accuracy: 0.0000e+00 - val_loss: 3.6693 - val_accuracy: 0.0000e+00\n",
      "Epoch 210/250\n",
      "7/7 [==============================] - 4s 597ms/step - loss: 7.4931 - accuracy: 0.0000e+00 - val_loss: 3.7161 - val_accuracy: 0.0000e+00\n",
      "Epoch 211/250\n",
      "7/7 [==============================] - 4s 587ms/step - loss: 7.0676 - accuracy: 0.0000e+00 - val_loss: 3.6118 - val_accuracy: 0.0000e+00\n",
      "Epoch 212/250\n",
      "7/7 [==============================] - 4s 624ms/step - loss: 7.5066 - accuracy: 0.0000e+00 - val_loss: 3.8290 - val_accuracy: 0.0000e+00\n",
      "Epoch 213/250\n",
      "7/7 [==============================] - 4s 616ms/step - loss: 6.9553 - accuracy: 0.0000e+00 - val_loss: 4.2132 - val_accuracy: 0.0000e+00\n",
      "Epoch 214/250\n",
      "7/7 [==============================] - 4s 591ms/step - loss: 7.8085 - accuracy: 0.0000e+00 - val_loss: 3.5910 - val_accuracy: 0.0000e+00\n",
      "Epoch 215/250\n",
      "7/7 [==============================] - 5s 706ms/step - loss: 7.1043 - accuracy: 0.0000e+00 - val_loss: 4.0670 - val_accuracy: 0.0000e+00\n",
      "Epoch 216/250\n",
      "7/7 [==============================] - 5s 676ms/step - loss: 6.8651 - accuracy: 0.0000e+00 - val_loss: 4.2089 - val_accuracy: 0.0000e+00\n",
      "Epoch 217/250\n",
      "7/7 [==============================] - 4s 589ms/step - loss: 7.8790 - accuracy: 0.0000e+00 - val_loss: 4.0448 - val_accuracy: 0.0000e+00\n",
      "Epoch 218/250\n",
      "7/7 [==============================] - 4s 587ms/step - loss: 7.7604 - accuracy: 0.0000e+00 - val_loss: 3.6074 - val_accuracy: 0.0000e+00\n",
      "Epoch 219/250\n",
      "7/7 [==============================] - 4s 601ms/step - loss: 7.5130 - accuracy: 0.0000e+00 - val_loss: 3.9630 - val_accuracy: 0.0000e+00\n",
      "Epoch 220/250\n",
      "7/7 [==============================] - 4s 627ms/step - loss: 7.8314 - accuracy: 0.0000e+00 - val_loss: 3.9716 - val_accuracy: 0.0000e+00\n",
      "Epoch 221/250\n",
      "7/7 [==============================] - 4s 600ms/step - loss: 7.3644 - accuracy: 0.0000e+00 - val_loss: 3.8698 - val_accuracy: 0.0000e+00\n",
      "Epoch 222/250\n",
      "7/7 [==============================] - 4s 583ms/step - loss: 7.6092 - accuracy: 0.0000e+00 - val_loss: 3.7253 - val_accuracy: 0.0000e+00\n",
      "Epoch 223/250\n",
      "7/7 [==============================] - 4s 602ms/step - loss: 7.2619 - accuracy: 0.0000e+00 - val_loss: 3.7840 - val_accuracy: 0.0000e+00\n",
      "Epoch 224/250\n",
      "7/7 [==============================] - 4s 612ms/step - loss: 7.1769 - accuracy: 0.0000e+00 - val_loss: 3.5428 - val_accuracy: 0.0000e+00\n",
      "Epoch 225/250\n",
      "7/7 [==============================] - 4s 587ms/step - loss: 7.7343 - accuracy: 0.0000e+00 - val_loss: 3.5496 - val_accuracy: 0.0000e+00\n",
      "Epoch 226/250\n",
      "7/7 [==============================] - 4s 587ms/step - loss: 6.7167 - accuracy: 0.0000e+00 - val_loss: 3.7119 - val_accuracy: 0.0000e+00\n",
      "Epoch 227/250\n",
      "7/7 [==============================] - 4s 602ms/step - loss: 7.2883 - accuracy: 0.0000e+00 - val_loss: 3.5623 - val_accuracy: 0.0000e+00\n",
      "Epoch 228/250\n",
      "7/7 [==============================] - 4s 583ms/step - loss: 6.8014 - accuracy: 0.0000e+00 - val_loss: 3.7417 - val_accuracy: 0.0000e+00\n",
      "Epoch 229/250\n",
      "7/7 [==============================] - 4s 597ms/step - loss: 6.5450 - accuracy: 0.0000e+00 - val_loss: 4.5386 - val_accuracy: 0.0000e+00\n",
      "Epoch 230/250\n",
      "7/7 [==============================] - 4s 626ms/step - loss: 7.4058 - accuracy: 0.0000e+00 - val_loss: 3.8694 - val_accuracy: 0.0000e+00\n",
      "Epoch 231/250\n",
      "7/7 [==============================] - 4s 605ms/step - loss: 6.9607 - accuracy: 0.0000e+00 - val_loss: 3.9000 - val_accuracy: 0.0000e+00\n",
      "Epoch 232/250\n",
      "7/7 [==============================] - 4s 589ms/step - loss: 7.5170 - accuracy: 0.0000e+00 - val_loss: 3.5905 - val_accuracy: 0.0000e+00\n",
      "Epoch 233/250\n",
      "7/7 [==============================] - 4s 581ms/step - loss: 7.3061 - accuracy: 0.0000e+00 - val_loss: 3.6251 - val_accuracy: 0.0000e+00\n",
      "Epoch 234/250\n",
      "7/7 [==============================] - 4s 583ms/step - loss: 6.9570 - accuracy: 0.0000e+00 - val_loss: 3.6014 - val_accuracy: 0.0000e+00\n",
      "Epoch 235/250\n",
      "7/7 [==============================] - 4s 583ms/step - loss: 7.4174 - accuracy: 0.0000e+00 - val_loss: 3.7794 - val_accuracy: 0.0000e+00\n",
      "Epoch 236/250\n",
      "7/7 [==============================] - 4s 581ms/step - loss: 6.8759 - accuracy: 0.0000e+00 - val_loss: 4.1523 - val_accuracy: 0.0000e+00\n",
      "Epoch 237/250\n",
      "7/7 [==============================] - 4s 581ms/step - loss: 7.1324 - accuracy: 0.0000e+00 - val_loss: 3.7831 - val_accuracy: 0.0000e+00\n",
      "Epoch 238/250\n",
      "7/7 [==============================] - 4s 577ms/step - loss: 6.9945 - accuracy: 0.0000e+00 - val_loss: 3.7462 - val_accuracy: 0.0000e+00\n",
      "Epoch 239/250\n",
      "7/7 [==============================] - 4s 584ms/step - loss: 6.7750 - accuracy: 0.0000e+00 - val_loss: 3.5914 - val_accuracy: 0.0000e+00\n",
      "Epoch 240/250\n",
      "7/7 [==============================] - 4s 583ms/step - loss: 7.0208 - accuracy: 0.0000e+00 - val_loss: 3.5424 - val_accuracy: 0.0000e+00\n",
      "Epoch 241/250\n",
      "7/7 [==============================] - 4s 600ms/step - loss: 7.1802 - accuracy: 0.0000e+00 - val_loss: 3.7860 - val_accuracy: 0.0000e+00\n",
      "Epoch 242/250\n",
      "7/7 [==============================] - 4s 584ms/step - loss: 7.3596 - accuracy: 0.0000e+00 - val_loss: 3.5576 - val_accuracy: 0.0000e+00\n",
      "Epoch 243/250\n",
      "7/7 [==============================] - 4s 598ms/step - loss: 6.5230 - accuracy: 0.0000e+00 - val_loss: 3.6600 - val_accuracy: 0.0000e+00\n",
      "Epoch 244/250\n",
      "7/7 [==============================] - 4s 581ms/step - loss: 6.7213 - accuracy: 0.0000e+00 - val_loss: 3.8406 - val_accuracy: 0.0000e+00\n",
      "Epoch 245/250\n",
      "7/7 [==============================] - 4s 590ms/step - loss: 7.3997 - accuracy: 0.0000e+00 - val_loss: 3.5246 - val_accuracy: 0.0000e+00\n",
      "Epoch 246/250\n",
      "7/7 [==============================] - 4s 599ms/step - loss: 6.2125 - accuracy: 0.0000e+00 - val_loss: 4.0215 - val_accuracy: 0.0000e+00\n",
      "Epoch 247/250\n",
      "7/7 [==============================] - 4s 585ms/step - loss: 7.1195 - accuracy: 0.0000e+00 - val_loss: 3.8266 - val_accuracy: 0.0000e+00\n",
      "Epoch 248/250\n",
      "7/7 [==============================] - 4s 581ms/step - loss: 6.9817 - accuracy: 0.0000e+00 - val_loss: 3.7572 - val_accuracy: 0.0000e+00\n",
      "Epoch 249/250\n",
      "7/7 [==============================] - 4s 588ms/step - loss: 7.4532 - accuracy: 0.0000e+00 - val_loss: 3.9272 - val_accuracy: 0.0000e+00\n",
      "Epoch 250/250\n",
      "7/7 [==============================] - 4s 596ms/step - loss: 6.7321 - accuracy: 0.0000e+00 - val_loss: 3.5507 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fee9e1cc190>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#labels = tf.expand_dims(labels, axis=-1)\n",
    "opt = Adam(lr=0.0005)\n",
    "model.compile(optimizer=opt,loss=\"mse\", metrics=[\"accuracy\"])\n",
    "model.fit(x=x_train,y=y_train, epochs=250, batch_size=128, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-24T03:32:02.524589Z",
     "iopub.status.busy": "2021-02-24T03:32:02.524347Z",
     "iopub.status.idle": "2021-02-24T03:32:02.700485Z",
     "shell.execute_reply": "2021-02-24T03:32:02.699527Z",
     "shell.execute_reply.started": "2021-02-24T03:32:02.524562Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 3.4035 - accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluate on test data\")\n",
    "x_test = x_test.reshape(-1, 128, 128, 1)\n",
    "results = model.evaluate(x_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-24T03:32:02.701948Z",
     "iopub.status.busy": "2021-02-24T03:32:02.701655Z",
     "iopub.status.idle": "2021-02-24T03:32:04.404766Z",
     "shell.execute_reply": "2021-02-24T03:32:04.404057Z",
     "shell.execute_reply.started": "2021-02-24T03:32:02.701921Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 1s 47ms/step\n",
      "4/4 [==============================] - 0s 37ms/step\n"
     ]
    }
   ],
   "source": [
    "train_pred = model.predict(x_train,verbose=1)\n",
    "test_pred = model.predict(x_test,verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6a575403d4de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Test data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "\n",
    "ax.scatter(y_train,train_pred,s=5,marker=\".\",label='Training data')\n",
    "ax.scatter(y_test,test_pred,s=5,marker=\".\",label='Test data')\n",
    "\n",
    "lims = [\n",
    "    np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n",
    "    np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n",
    "]\n",
    "\n",
    "# now plot both limits against eachother\n",
    "ax.plot(lims, lims, 'k-', alpha=0.5, zorder=200)\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlim(lims)\n",
    "ax.set_ylim(lims)\n",
    "\n",
    "ax.set_xlabel('Original Radius')\n",
    "ax.set_ylabel('CNN Radius')\n",
    "ticks = np.arange(10,51,5)\n",
    "ax.set_xticks(ticks),ax.set_yticks(ticks)\n",
    "plt.title('Shifted',fontsize=15)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('1to1_plot_radius_approx-shift.png',dpi=250,bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
